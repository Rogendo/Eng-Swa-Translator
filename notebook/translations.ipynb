{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-18 19:46:39.790029: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-18 19:46:39.790293: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-18 19:46:40.071964: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-18 19:46:40.302141: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-18 19:46:45.509515: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "\n",
    "# translator pipeline for english to swahili translations\n",
    "eng_swa_model_checkpoint = \"Helsinki-NLP/opus-mt-en-swc\"\n",
    "eng_swa_tokenizer = AutoTokenizer.from_pretrained(\"../model/eng_swa_model/\")\n",
    "eng_swa_model = AutoModelForSeq2SeqLM.from_pretrained(\"../model/eng_swa_model/\")\n",
    "\n",
    "eng_swa_translator = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=eng_swa_model,\n",
    "    tokenizer=eng_swa_tokenizer,\n",
    ")\n",
    "\n",
    "def translate_text_eng_swa(text):\n",
    "    translated_text = eng_swa_translator(text, max_length=128, num_beams=5)[0]['generated_text']\n",
    "    return translated_text\n",
    "\n",
    "# translator pipeline for swahili to english translations\n",
    "swa_eng_model_checkpoint = \"Helsinki-NLP/opus-mt-swc-en\"\n",
    "swa_eng_tokenizer = AutoTokenizer.from_pretrained(\"../model/swa_eng_model/\")\n",
    "swa_eng_model = AutoModelForSeq2SeqLM.from_pretrained(\"../model/swa_eng_model/\")\n",
    "\n",
    "swa_eng_translator = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=swa_eng_model,\n",
    "    tokenizer=swa_eng_tokenizer,\n",
    ")\n",
    "\n",
    "def translate_text_swa_eng(text):\n",
    "    translated_text = swa_eng_translator(text, max_length=128, num_beams=5)[0]['generated_text']\n",
    "    return translated_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy_langdetect.spacy_langdetect.LanguageDetector at 0x7f16bcba2e90>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.language import Language\n",
    "from spacy_langdetect import LanguageDetector\n",
    "\n",
    "\n",
    "# Language detector\n",
    "def get_lang_detector(nlp, name):\n",
    "    return LanguageDetector()\n",
    "\n",
    "# # Load the English language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# # Register the language detection factory\n",
    "Language.factory(\"language_detector\", func=get_lang_detector)\n",
    "\n",
    "# # Add the language detection component to the pipeline\n",
    "nlp.add_pipe('language_detector', last=True)\n",
    "\n",
    "# res=\"We went to the club for drinks. We were so drunk\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: sw\n",
      "God created the universe in six days and on the seventh day, resting\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def write_to_csv(user_input,translated_text, correct_translation):\n",
    "    # Create a CSV file\n",
    "    with open('../incorrect_translations/translations.csv', 'a', newline='') as file:\n",
    "        # Create a CSV writer\n",
    "        writer = csv.writer(file)\n",
    "\n",
    "        # Check if the file is empty, i.e., it does not have a header row yet\n",
    "        if os.path.getsize('../incorrect_translations/translations.csv') == 0:\n",
    "            # Write the column header to the file\n",
    "            writer.writerow(['User Input', 'Translated Text', 'Correct Translation'])\n",
    "\n",
    "\n",
    "        # Write the data to the CSV file\n",
    "        writer.writerow([ user_input, translated_text, correct_translation])\n",
    "\n",
    "\n",
    "user_text=\"Early that morning, I was sick in my stomach. The stomach pain was killing me and I had no pain killers. I had to go to the hospital.\"\n",
    "# user_text= \"Mungu aliumba ulimwengu kwa siku sita na siku ya saba, akapumzika\"\n",
    "# user_text=\"\"\"\n",
    "# Asubuhi hiyo ilitupata pambajioni pa hospitali ya Uguzwa. Kando yangu ndugu yangu Pendo alikuwa akijipindapinda kwa uchungu mwingi. Aidha, alikuwa akitetemeka sana. Nilimshikilia asije akaanguka chini. Nilijizuia nisimtazame maadamu kila nilipomtaza machozi yalinidondoka. Nakwambia Pendo alikuwa amedhoofika sana. Maradhi hayo ya kifo yalikuwa yamemdhilisha akabaki gofu la mtu. Alikuwa kakonda ghaya ya kukonda akabaki fremu. Nilitokwa na milizamu ya machozi kwa huruma. Nilihisi kama kwamba mimi ndimi nilikuwa nikiugua. Ama kwa hakika damu ni nzito kuliko maji.\n",
    "# Siku hiyo mimi na ndugu yangu tuliratibiwa kufanyiwa upasuaji. Maadami figo zake zote zilikuwa zimeharibika, ningempa figo yangu moja kulingana na ripoti ya madaktari. Hiyo ndiyo ingekuwa njia ya pekee ya kusaidia la sivyo angetuacha. Mimi na yeye tulikuwa ndugu wa toka nitoke. Tulipendana mithili ya pete na kidole. Mintaarafu na hayo, nilikuwa nimejitolea mhanga kumpa ndugu yangu figo yangu.\n",
    "# Tukiwa tungali tumeketi, nilitoa simu yangu na kuanza kusakurasakura mitandaoni kuhusu ufadhili wa figo; hasara na manufaa yake. Yale niliyoyaona yaliniatua moyo pakubwa. Ilisemekana kuwa ilikuwa muhali kwa mtu mwenye figo moja kuishi kwa zaidi ya miaka ishirini. Mwili wangu mzima uliota vimbimbi kwa woga. Nilihofia kuwa huenda nisingefikisha umri wa miaka umri wa miaka thelathini na mitano. Moyo ulikuwa ukipigapiga mithili ya nyundo ya mhunzi kwenye fuawe.\n",
    "# Kwa upande mwingine nilimtupia jicho ndugu yangu aliyekuwa hajifai kwa maumivu. Nilimhurumia sana. Aidha, nilikumbuka msemo kuwa mla nawe hafi nawe ila mzaliwa nawe. Huo ndio ulikuwa wasaa wangu wa kuudhihirisha udugu wangu. Nisingemfaa wakati wa dhiki nisingekuwa rafiki shakiki. Vilevile nilikumbuka kuwa udugu ni kufaana wala si kufanana. Ijapokuwa tulikuwa maziwa na tui sikuwa na budi kumfaa.\n",
    "# Ndugu, jamaa na marafiki walitujia kutujulia hali na kututakia kila la heri. Nilituhumu kuwa pengine baadhi yao walikuja kutuona kwa mara ya mwisho. ' Msalie mtume. Mbona niyapitie haya? Ya nini nife nikiwa mchanga hivi hata ubwabwa haujanitoka shingoni? Hayo na mengine mengi yalikuwa tu baadhi ya maswali ya balagha yaliyonipitia akilini. \n",
    "# \"\"\"\n",
    "# user_text=\"Njeru, a master of deception, was known for tricking other animals into thinking he was a slower creature. This made him an outcast in the animal kingdom, and he often felt alone.\"\n",
    "# user_text=\"Njeru eventually decided to join forces with Kiume. The two formed an unbreakable bond, with Njeru vowing to change his ways and start treating others with respect.\"\n",
    "# user_text=\"Kiume, sensing Njeru's loneliness, offered his friendship. At first, Njeru hesitated, remembering the tricks he had played on others. But as time went by, he found himself growing fonder of Kiume.\"\n",
    "# user_text=\"You can access its rows, columns, and data by using standard indexing or by using column headers\"\n",
    "# user_text = \"\"\"\n",
    "# Once upon a time in a small town, there was a little girl named Lily who loved going to school. Every morning, she would put on her favorite pink backpack and skip down the road to the cheerful school building. In Lily's class, there was a kind and friendly teacher named Mrs. Johnson. Mrs. Johnson had a big smile that made everyone feel happy. The classroom was filled with colorful posters, and there was a cozy reading corner with soft cushions. One sunny day, Mrs. Johnson announced a special project. The class was going to create a magical garden in the schoolyard. Each student would bring a flower or a plant to contribute to the garden.\n",
    "# \"\"\"\n",
    "# language detector here\n",
    "\n",
    "# language detection\n",
    "doc=nlp(user_text)\n",
    "detected_language = doc._.language['language']\n",
    "print(f\"Detected language: {detected_language}\")   \n",
    "\n",
    "if detected_language==\"en\":   \n",
    "    translated_text=translate_text_eng_swa(user_text)\n",
    "    print(translate_text_eng_swa(user_text))\n",
    "elif detected_language=='sw':\n",
    "    translated_text=translate_text_swa_eng(user_text)\n",
    "    print(translate_text_swa_eng(user_text))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "is_translation_correct = input(\"Is translation correct? \")\n",
    "# is_translation_correct = bool(is_translation_correct)\n",
    "if is_translation_correct.lower()=='yes': # If is_translation_correct is True\n",
    "    print(\"correct translation\")\n",
    "    \n",
    "elif  is_translation_correct.lower()=='no': # If is_translation_correct is False\n",
    "    corrected_text = input(\"Enter the corrected text: \")\n",
    "    \n",
    "    print(\"correct translation \" + corrected_text)\n",
    "    write_to_csv(user_text, translated_text, corrected_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # proprocess the saved csv file \n",
    "# def preprocess_csv(file):\n",
    "#     import pandas as pd\n",
    "#     df = pd.read_csv(file)\n",
    "#     # remove rows with missing values (NaN or None)\n",
    "#     df = df.dropna()\n",
    "#     # df = df.\n",
    "#     return df\n",
    "\n",
    "# data = open('../incorrect_translations/translations.csv')\n",
    "# preprocess_csv(data)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User Input</th>\n",
       "      <th>Translated Text</th>\n",
       "      <th>Correct Translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what was the original crime</td>\n",
       "      <td>Uhalifu wa awali ulisababishwa na nini?</td>\n",
       "      <td>uhalifu wa kwanza ulikuwa?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kiume, sensing Njeru's loneliness, offered his...</td>\n",
       "      <td>Kiume, ambaye alitambua upweke wa Njeru, alito...</td>\n",
       "      <td>Kiume ambaye alitambua upweke wa Njeru, alijit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kiume, sensing Njeru's loneliness, offered his...</td>\n",
       "      <td>Kiume, ambaye alitambua upweke wa Njeru, alito...</td>\n",
       "      <td>Kiume, ambaye alitambua upweke wa Njeru, aliji...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Njeru eventually decided to join forces with K...</td>\n",
       "      <td>Mwishowe Njeru aliamua kujiunga na jeshi la Kiume</td>\n",
       "      <td>Mwishowe Njeru aliamua kujiunga na Kiume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Njeru eventually decided to join forces with K...</td>\n",
       "      <td>Mwishowe Njeru aliamua kujiunga na majeshi pam...</td>\n",
       "      <td>Mwishowe Njeru aliamua kujiunga pamoja na Kium...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I love going to school because I get to play w...</td>\n",
       "      <td>Mimi hupenda kwenda shuleni kwa sababu ninaanz...</td>\n",
       "      <td>Ninapenda kuenda shule kwa sababu ninapata kuc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I love going to school because I get to play w...</td>\n",
       "      <td>Mimi hupenda kwenda shuleni kwa sababu ninaanz...</td>\n",
       "      <td>Ninapenda kuenda shule kwa sababu ninapata kuc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Early that morning, I was sick in my stomach. ...</td>\n",
       "      <td>Mapema asubuhi hiyo, nilikuwa mgonjwa tumboni ...</td>\n",
       "      <td>Mapema asubuhi hiyo, nilikuwa mgonjwa tumboni ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I love going to school because I get to play w...</td>\n",
       "      <td>Mimi hupenda kwenda shuleni kwa sababu ninaanz...</td>\n",
       "      <td>Mimi hupenda kwenda shuleni kwa sababu nanapat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Nilipeleka ng'ombe kichinjioni</td>\n",
       "      <td>I took a cow to a knnin</td>\n",
       "      <td>I took the cow to the slaughter house</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mungu aliumba ulimwengu kwa siku sita na siku ...</td>\n",
       "      <td>God created the universe in six days and on th...</td>\n",
       "      <td>God created the universe in six days and on th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           User Input  \\\n",
       "0                        what was the original crime    \n",
       "1   Kiume, sensing Njeru's loneliness, offered his...   \n",
       "2   Kiume, sensing Njeru's loneliness, offered his...   \n",
       "3   Njeru eventually decided to join forces with K...   \n",
       "4   Njeru eventually decided to join forces with K...   \n",
       "5   I love going to school because I get to play w...   \n",
       "6   I love going to school because I get to play w...   \n",
       "7   Early that morning, I was sick in my stomach. ...   \n",
       "8   I love going to school because I get to play w...   \n",
       "9                      Nilipeleka ng'ombe kichinjioni   \n",
       "10  Mungu aliumba ulimwengu kwa siku sita na siku ...   \n",
       "\n",
       "                                      Translated Text  \\\n",
       "0             Uhalifu wa awali ulisababishwa na nini?   \n",
       "1   Kiume, ambaye alitambua upweke wa Njeru, alito...   \n",
       "2   Kiume, ambaye alitambua upweke wa Njeru, alito...   \n",
       "3   Mwishowe Njeru aliamua kujiunga na jeshi la Kiume   \n",
       "4   Mwishowe Njeru aliamua kujiunga na majeshi pam...   \n",
       "5   Mimi hupenda kwenda shuleni kwa sababu ninaanz...   \n",
       "6   Mimi hupenda kwenda shuleni kwa sababu ninaanz...   \n",
       "7   Mapema asubuhi hiyo, nilikuwa mgonjwa tumboni ...   \n",
       "8   Mimi hupenda kwenda shuleni kwa sababu ninaanz...   \n",
       "9                             I took a cow to a knnin   \n",
       "10  God created the universe in six days and on th...   \n",
       "\n",
       "                                  Correct Translation  \n",
       "0                          uhalifu wa kwanza ulikuwa?  \n",
       "1   Kiume ambaye alitambua upweke wa Njeru, alijit...  \n",
       "2   Kiume, ambaye alitambua upweke wa Njeru, aliji...  \n",
       "3            Mwishowe Njeru aliamua kujiunga na Kiume  \n",
       "4   Mwishowe Njeru aliamua kujiunga pamoja na Kium...  \n",
       "5   Ninapenda kuenda shule kwa sababu ninapata kuc...  \n",
       "6   Ninapenda kuenda shule kwa sababu ninapata kuc...  \n",
       "7   Mapema asubuhi hiyo, nilikuwa mgonjwa tumboni ...  \n",
       "8   Mimi hupenda kwenda shuleni kwa sababu nanapat...  \n",
       "9               I took the cow to the slaughter house  \n",
       "10  God created the universe in six days and on th...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"../incorrect_translations/translations.csv\")\n",
    "# remove rows with missing values (NaN or None)\n",
    "df = df.dropna()\n",
    "df \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User Input</th>\n",
       "      <th>Correct Translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what was the original crime</td>\n",
       "      <td>uhalifu wa kwanza ulikuwa?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kiume, sensing Njeru's loneliness, offered his...</td>\n",
       "      <td>Kiume ambaye alitambua upweke wa Njeru, alijit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kiume, sensing Njeru's loneliness, offered his...</td>\n",
       "      <td>Kiume, ambaye alitambua upweke wa Njeru, aliji...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Njeru eventually decided to join forces with K...</td>\n",
       "      <td>Mwishowe Njeru aliamua kujiunga na Kiume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Njeru eventually decided to join forces with K...</td>\n",
       "      <td>Mwishowe Njeru aliamua kujiunga pamoja na Kium...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I love going to school because I get to play w...</td>\n",
       "      <td>Ninapenda kuenda shule kwa sababu ninapata kuc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I love going to school because I get to play w...</td>\n",
       "      <td>Ninapenda kuenda shule kwa sababu ninapata kuc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Early that morning, I was sick in my stomach. ...</td>\n",
       "      <td>Mapema asubuhi hiyo, nilikuwa mgonjwa tumboni ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I love going to school because I get to play w...</td>\n",
       "      <td>Mimi hupenda kwenda shuleni kwa sababu nanapat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Nilipeleka ng'ombe kichinjioni</td>\n",
       "      <td>I took the cow to the slaughter house</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mungu aliumba ulimwengu kwa siku sita na siku ...</td>\n",
       "      <td>God created the universe in six days and on th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           User Input  \\\n",
       "0                        what was the original crime    \n",
       "1   Kiume, sensing Njeru's loneliness, offered his...   \n",
       "2   Kiume, sensing Njeru's loneliness, offered his...   \n",
       "3   Njeru eventually decided to join forces with K...   \n",
       "4   Njeru eventually decided to join forces with K...   \n",
       "5   I love going to school because I get to play w...   \n",
       "6   I love going to school because I get to play w...   \n",
       "7   Early that morning, I was sick in my stomach. ...   \n",
       "8   I love going to school because I get to play w...   \n",
       "9                      Nilipeleka ng'ombe kichinjioni   \n",
       "10  Mungu aliumba ulimwengu kwa siku sita na siku ...   \n",
       "\n",
       "                                  Correct Translation  \n",
       "0                          uhalifu wa kwanza ulikuwa?  \n",
       "1   Kiume ambaye alitambua upweke wa Njeru, alijit...  \n",
       "2   Kiume, ambaye alitambua upweke wa Njeru, aliji...  \n",
       "3            Mwishowe Njeru aliamua kujiunga na Kiume  \n",
       "4   Mwishowe Njeru aliamua kujiunga pamoja na Kium...  \n",
       "5   Ninapenda kuenda shule kwa sababu ninapata kuc...  \n",
       "6   Ninapenda kuenda shule kwa sababu ninapata kuc...  \n",
       "7   Mapema asubuhi hiyo, nilikuwa mgonjwa tumboni ...  \n",
       "8   Mimi hupenda kwenda shuleni kwa sababu nanapat...  \n",
       "9               I took the cow to the slaughter house  \n",
       "10  God created the universe in six days and on th...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # drop the 'Translated Text' column\n",
    "\n",
    "df = df.drop('Translated Text', axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User Input</th>\n",
       "      <th>Correct Translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what was the original crime</td>\n",
       "      <td>uhalifu wa kwanza ulikuwa?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kiume, sensing Njeru's loneliness, offered his...</td>\n",
       "      <td>Kiume ambaye alitambua upweke wa Njeru, alijit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kiume, sensing Njeru's loneliness, offered his...</td>\n",
       "      <td>Kiume, ambaye alitambua upweke wa Njeru, aliji...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Njeru eventually decided to join forces with K...</td>\n",
       "      <td>Mwishowe Njeru aliamua kujiunga na Kiume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Njeru eventually decided to join forces with K...</td>\n",
       "      <td>Mwishowe Njeru aliamua kujiunga pamoja na Kium...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          User Input  \\\n",
       "0                       what was the original crime    \n",
       "1  Kiume, sensing Njeru's loneliness, offered his...   \n",
       "2  Kiume, sensing Njeru's loneliness, offered his...   \n",
       "3  Njeru eventually decided to join forces with K...   \n",
       "4  Njeru eventually decided to join forces with K...   \n",
       "\n",
       "                                 Correct Translation  \n",
       "0                         uhalifu wa kwanza ulikuwa?  \n",
       "1  Kiume ambaye alitambua upweke wa Njeru, alijit...  \n",
       "2  Kiume, ambaye alitambua upweke wa Njeru, aliji...  \n",
       "3           Mwishowe Njeru aliamua kujiunga na Kiume  \n",
       "4  Mwishowe Njeru aliamua kujiunga pamoja na Kium...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "# !pip install datasets\n",
    "# !pip install sentencepiece\n",
    "# !pip install transformers[torch]\n",
    "# !pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "import sentencepiece\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 loading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "876050e38b1e489c8781735c863cde51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b871571d81ad45e7b93f9df7db3734fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf68d0ec4f77491a883e302f3c07038c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# loading the csv dataset\n",
    "df = load_dataset(\"csv\", data_files=\"../incorrect_translations/translations.csv\")\n",
    "# # drop the 'Translated Text' column\n",
    "df=df.remove_columns('Translated Text')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 viewing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset object:\n",
      "\n",
      " DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['User Input', 'Correct Translation'],\n",
      "        num_rows: 11\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset object:\\n\\n\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Viewing the information about the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset information:\n",
      "\n",
      " {'User Input': Value(dtype='string', id=None), 'Correct Translation': Value(dtype='string', id=None)}\n"
     ]
    }
   ],
   "source": [
    "train_dataset = df['train']\n",
    "print(\"Train dataset information:\\n\\n\", train_dataset.features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4  Viewing the split dataset information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Split datasets:\n",
      "\n",
      " DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['User Input', 'Correct Translation'],\n",
      "        num_rows: 9\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['User Input', 'Correct Translation'],\n",
      "        num_rows: 2\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "split_df = df['train'].train_test_split(train_size=0.9, seed=20)\n",
    "print(\"\\nSplit datasets:\\n\\n\", split_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 1.5 Loading the tokenizer and saved model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"Helsinki-NLP/opus-mt-en-swc\"\n",
    "eng_swa_tokenizer = AutoTokenizer.from_pretrained(\"../model/eng_swa_model/\")\n",
    "eng_swa_model = AutoModelForSeq2SeqLM.from_pretrained(\"../model/eng_swa_model/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6 Set the maximum sequence length and define the preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 128\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = str(examples['User Input'])\n",
    "    targets = str(examples['Correct Translation'])\n",
    "    \n",
    "    model_inputs = eng_swa_tokenizer(\n",
    "        inputs, text_target=targets, max_length=max_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\"\n",
    "    )\n",
    "    model_inputs['decoder_input_ids'] = model_inputs['input_ids'].clone()\n",
    "\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.7 Preprocess the training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c567839c2aa4fa68da314758b1996c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/9 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = split_df['train'].map(\n",
    "    preprocess_function, batched=True, num_proc=4, remove_columns=[\"User Input\",\"Correct Translation\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96f563c802854b31843a3e73355fa8e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_dataset = split_df['test'].map(\n",
    "    preprocess_function, batched=True, remove_columns=[\"User Input\", \"Correct Translation\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.8 Define the training arguments and create the trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir='../retrained_model/',\n",
    "    predict_with_generate=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=1000,\n",
    "    save_steps=1000,\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=20,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=False,\n",
    "    logging_dir=\"../retrained_model_logs/\",\n",
    "    logging_steps=500,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=eng_swa_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.9  Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89098560e3d24ca1b79f8c1e101193d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    trainer.train()\n",
    "except ValueError as e:\n",
    "    print(\"Error during training:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.10 Evaluate the model on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9e39484bc08409c801887bee3456dff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5209457874298096, 'eval_runtime': 0.865, 'eval_samples_per_second': 1.156, 'eval_steps_per_second': 1.156, 'epoch': 20.0}\n"
     ]
    }
   ],
   "source": [
    "result = trainer.evaluate()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.0 Export the retrained-pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../retrained_model/tokenizer_config.json',\n",
       " '../retrained_model/special_tokens_map.json',\n",
       " '../retrained_model/vocab.json',\n",
       " '../retrained_model/source.spm',\n",
       " '../retrained_model/target.spm',\n",
       " '../retrained_model/added_tokens.json')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_swa_model.save_pretrained(\"../retrained_model/\")\n",
    "eng_swa_tokenizer.save_pretrained(\"../retrained_model/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Creating a pipeline for translation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=\"../retrained_model/\",\n",
    "    tokenizer=\"../retrained_model/\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated text: Mimi hupenda kwenda shuleni kwa sababu ninaanza kucheza na marafiki wangu\n",
      "Translated text: Mapema asubuhi hiyo, nilikuwa mgonjwa tumboni na maumivu ya tumbo yalikuwa yakiniua na sikuwa na wauaji wa maumivu, hivyo ilinibidi kwenda hospitalini.\n",
      "Translated text: Uhalifu wa awali ulikuwa nini?\n",
      "Translated text: \"umeume, ambaye alitambua upweke wa Njeru, alitaka kuwa rafiki yake., kwanza, Njeru alisitasita, huku akikumbuka mbinu aliyokuwa amecheza juu ya wengine.\n",
      "Translated text: â†‘\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    text = input(\"Enter an English sentence for translation to Swahili (type 'exit' to quit): \")\n",
    "    if text == \"exit\":\n",
    "        break\n",
    "    translated_text = translator(text, max_length=max_length, num_beams=5)[0]['generated_text']\n",
    "    print(f\"Translated text: {translated_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
